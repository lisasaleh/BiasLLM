#!/bin/bash
#SBATCH --job-name=ft_mt5_undersample
#SBATCH --output=logs/ft_mt5_undersample_%A.out
#SBATCH --error=logs/ft_mt5_undersample_%A.err
#SBATCH --partition=gpu_mig
#SBATCH --gpus=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=9
#SBATCH --time=01:00:00

module load 2023
module load Anaconda3/2023.07-2
source activate atics_p2

echo "Unistalling everything"
pip uninstall -y transformers tokenizers datasets accelerate huggingface-hub fsspec

echo "Installing correct transformers stack..."
pip install --upgrade --force-reinstall --no-cache-dir \
    transformers==4.36.2 \
    tokenizers==0.19.1 \
    datasets==2.14.0 \
    accelerate==1.7.0 \
    huggingface-hub>=0.30.0,<1.0.0 \
    fsspec==2023.6.0

echo "Dependencies installed."

cd $HOME/BiasLLM/mt5_classification

echo "Starting fine-tuning with seed 50..."
python pretraining_mt5_classification.py --sampling undersample --seed 50

echo "Starting fine-tuning with seed 51..."
python pretraining_mt5_classification.py --sampling undersample --seed 51

echo "Done."
